package com.comicgator

import java.security.MessageDigest

import com.typesafe.config.ConfigFactory
import com.typesafe.scalalogging.LazyLogging
import org.bson.types.ObjectId
import org.openqa.selenium.{By, WebDriver, WebElement}
import org.openqa.selenium.htmlunit.HtmlUnitDriver
import play.api.libs.functional.syntax._
import play.api.libs.json.{JsPath, JsValue, Json, Reads}
import slick.basic.DatabaseConfig
import slick.jdbc.{GetResult, JdbcProfile}

import scala.annotation.tailrec
import scala.collection.JavaConverters._
import scala.concurrent.duration.Duration
import scala.concurrent.{Await, ExecutionContext, Future}
import scala.io.Source
import scala.util.Random

/**
  * Package Object containing some implicit values for converting database
  * results and decoding json.
  */
package object lurker {
  implicit val getJsonResult: GetResult[JsValue] = GetResult(
    r => Json.parse(r.nextString))
  implicit val getObjectIdResult: GetResult[ObjectId] = GetResult(
    r => new ObjectId(r.nextString))
  implicit val ObjectIdReader: Reads[ObjectId] =
    JsPath.read[String].map(new ObjectId(_))
}

/**
  * Comic Class representing comic meta data and strategies for parsing
  * strips from comic website.
  * @param id Object id uniquely identifying a Comic.
  * @param hostname String usually the domain and tld of the comic website,
  *                 useful for matching or creating urls.
  * @param title String represents the general name of the comic.
  * @param creator String the name of the comic creator.
  * @param bannerImage String location of the pre-generated image representing
  *                    the comic in-app.
  * @param firstUrl String a url of the very first strip of the comic.
  *                 ETL starts here if delta is false.
  */
case class Comic(id: ObjectId,
                 hostname: String,
                 title: String,
                 creator: String,
                 isAdvertised: Boolean,
                 patreonUrl: Option[String],
                 store_url: Option[String],
                 bannerImage: String,
                 firstUrl: String,
                 strategy: Strategy)

case class Strategy(next: Vector[String],
                    image: Vector[String],
                    title: Option[Vector[String]],
                    imageTitle: Option[Vector[String]],
                    imageAlt: Option[Vector[String]],
                    bonusImage: Option[Vector[String]])

object Comic {
  import lurker.ObjectIdReader

  implicit val strategyReader: Reads[Strategy] =
    ((JsPath \ "next").read[Vector[String]] and
      (JsPath \ "image").read[Vector[String]] and
      (JsPath \ "title").readNullable[Vector[String]] and
      (JsPath \ "image_title").readNullable[Vector[String]] and
      (JsPath \ "image_alt").readNullable[Vector[String]] and
      (JsPath \ "bonus_image").readNullable[Vector[String]])(Strategy.apply _)

  implicit val comicReader: Reads[Comic] = ((JsPath \ "id").read[ObjectId] and
    (JsPath \ "hostname").read[String] and
    (JsPath \ "title").read[String] and
    (JsPath \ "creator").read[String] and
    (JsPath \ "is_advertised").read[Boolean] and
    (JsPath \ "patreon_url").readNullable[String] and
    (JsPath \ "store_url").readNullable[String] and
    (JsPath \ "banner_image").read[String] and
    (JsPath \ "first_url").read[String] and
    (JsPath \ "strategy").read[Strategy])(Comic.apply _)
}

/**
  * Object describing Comic Strip.
  * @param id Object id uniquely identifying a Strip.
  * @param comicId Comic Associated with the Strip.
  * @param thumbnailUrl String image url for a thumbnail to be eventually
  *                     generated by Lurker.
  * @param scrap Scrap class of values reaped from the html.
  */
case class Strip(id: ObjectId,
                 comicId: ObjectId,
                 thumbnailUrl: String,
                 scrap: Scrap)

/**
  * Object representing the outcome of the scraped comic strip webpage.
  * @param number Counter for tracking order of comics by release.
  * @param checksum String MD5 hash of the image url used for uniquely
  *                 identifying the comic.
  * @param imageUrls Vector of image url strings. (Required)
  * @param title String the text of the title.
  * @param bonusImageUrl String the url of the bonus image.
  * @param imageTitle String the text of the title text of the comic image.
  * @param imageAlt String the text of the alt text of the comic image.
  */
case class Scrap(number: Int,
                 checksum: String,
                 url: String,
                 imageUrls: Vector[String],
                 title: Option[String],
                 imageTitle: Option[String],
                 imageAlt: Option[String],
                 bonusImageUrl: Option[String],
                 isSpecial: Boolean)

/**
  * Repository for database persistence queries.
  * @param ex Execution Context
  */
class Repository()(implicit ex: ExecutionContext) {
  private val dbConfig: DatabaseConfig[JdbcProfile] =
    DatabaseConfig.forConfig("comic_database")
  private val profile: JdbcProfile = dbConfig.profile
  private val db: JdbcProfile#Backend#Database = dbConfig.db
  import profile.api._

  def shutdown(): Unit = db.close()

  /**
    * Inserts comic
    * @param comic Comic
    * @return
    */
  def insertComic(comic: Comic): Future[Int] = {
    db.run(sql"""
      INSERT INTO cg.comic (
        id,
        hostname,
        title,
        creator,
        is_advertised,
        patreon_url,
        store_url,
        banner_image,
        first_url)
      VALUES (
        ${comic.id.toString},
        ${comic.hostname},
        ${comic.title},
        ${comic.creator},
        ${comic.isAdvertised.toString}::BOOLEAN,
        ${comic.patreonUrl}::TEXT,
        ${comic.store_url}::TEXT,
        ${comic.bannerImage},
        ${comic.firstUrl})
      ON CONFLICT (id) DO UPDATE SET (
        id,
        hostname,
        title,
        creator,
        is_advertised,
        patreon_url,
        store_url,
        banner_image,
        first_url) = (
        ${comic.id.toString},
        ${comic.hostname},
        ${comic.title},
        ${comic.creator},
        ${comic.isAdvertised.toString}::BOOLEAN,
        ${comic.patreonUrl}::TEXT,
        ${comic.store_url}::TEXT,
        ${comic.bannerImage},
        ${comic.firstUrl})""".as[Int].head)
  }

  /**
    * Inserts comic strip
    * @param strip Strip
    * @return
    */
  def insertStrip(strip: Strip): Future[Int] = {
    db.run(sql"""
      INSERT INTO cg.strip (
        comic_id,
        checksum,
        number,
        url,
        image_urls,
        thumbnail_image_url,
        title,image_alt,
        image_title,
        bonus_image_url,
        is_special)
      VALUES (
        ${strip.comicId.toString},
        ${strip.scrap.checksum},
        ${strip.scrap.number},
        ${strip.scrap.url},
        ${strip.scrap.imageUrls.mkString("{\"", "\",\"", "\"}")}::TEXT[],
        ${strip.thumbnailUrl},
        ${strip.scrap.title}::TEXT,
        ${strip.scrap.imageAlt}::TEXT,
        ${strip.scrap.imageTitle}::TEXT,
        ${strip.scrap.bonusImageUrl}::TEXT,
        ${strip.scrap.isSpecial.toString}::BOOLEAN)
      ON CONFLICT (comic_id, number) DO UPDATE SET (
        comic_id,
        checksum,
        number,
        url,
        image_urls,
        thumbnail_image_url,
        title,image_alt,
        image_title,
        bonus_image_url,
        is_special) = (
        ${strip.comicId.toString},
        ${strip.scrap.checksum},
        ${strip.scrap.number},
        ${strip.scrap.url},
        ${strip.scrap.imageUrls.mkString("{\"", "\",\"", "\"}")}::TEXT[],
        ${strip.thumbnailUrl},
        ${strip.scrap.title}::TEXT,
        ${strip.scrap.imageAlt}::TEXT,
        ${strip.scrap.imageTitle}::TEXT,
        ${strip.scrap.bonusImageUrl}::TEXT,
        ${strip.scrap.isSpecial.toString}::BOOLEAN)""".as[Int].head)
  }

  /**
    * Finds the most recent comic strip.
    * @param comicId ObjectId
    * @param firstUrl String, first strip url of the comic
    * @return
    */
  def lastStrip(comicId: ObjectId, firstUrl: String): Future[(String, Int)] = {
    db.run(
        sql"""
      SELECT s.url, s.number FROM cg.strip s JOIN cg.comic c ON s.comic_id = c.id
      WHERE c.id = ${comicId.toString} ORDER BY s.number DESC LIMIT 1"""
          .as[(String, Int)]
          .headOption)
      .map {
        case Some((url, number)) => (url, number)
        case None => (firstUrl, 1)
      }
  }
}

/**
  * Configuration trait loads contents from application.conf file
  * and makes them available as a mixin.
  */
trait Conf {
  private val config = ConfigFactory.load()
  val ETL_BATCH_SIZE: Int = config.getInt("etl_batch_size")
  val IS_DELTA: Boolean = config.getBoolean("is_delta")
}

object Lurker extends App with Conf with LazyLogging {
  // Use single execution context for future sync.
  implicit val ec: ExecutionContext = ExecutionContext.global
  // Instantiate database access.
  private val repo = new Repository
  // Load comic configuration from json file.
  private val comics: Vector[Comic] = Json
    .fromJson[Vector[Comic]](
      Json.parse(Source.fromResource("comics.json").getLines().mkString))
    .get

  /**
    * Runs etl process for each comic concurrently.
    * @param comics Vector[Comic] Comics to run etl on.
    * @return
    */
  private def etl(comics: Vector[Comic]): Future[Vector[Boolean]] = {
    Future.sequence {
      for (comic <- comics)
        yield
          for {
            comicInsert <- repo.insertComic(comic)
            (startUrl, count) <- startingPoint(comicInsert, comic)
            scraps <- extract(startUrl, count, comic.strategy)
            strips <- transform(comic, scraps)
            stripInsert <- load(strips)
          } yield {
            logger.info(s"Inserted ${stripInsert.sum} comic strips")
            true
          }
    }
  }

  /**
    * Starting point determines which page to start scraping with.
    * @param comic Comic
    * @return
    */
  private def startingPoint(comicInsert: Int,
                            comic: Comic): Future[(String, Int)] = {
    logger.info(s"Inserted $comicInsert comic id: ${comic.id}")
    logger.info(s"Starting comic: ${comic.title}")
    if (IS_DELTA) {
      repo.lastStrip(comic.id, comic.firstUrl)
    } else {
      Future.successful(comic.firstUrl, 1)
    }
  }

  /**
    * extract
    * @param startUrl String beginning url to be scraped.
    * @param startCount Int Associated number of that strip.
    * @param strategy patterns for scraping.
    * @return Future List of Strip objects
    */
  private def extract(startUrl: String,
                      startCount: Int,
                      strategy: Strategy): Future[Vector[Scrap]] = Future {
    val driver = new HtmlUnitDriver()

    /**
      * A crawl closure to recurse on after the client is initialized.
      * @param target String of the url currently targeted.
      * @param count Int counter for associating numbers to the strips.
      * @param scraps Collection of Scrap objects returned from the crawl.
      * @return List of Scrap objects.
      */
    @tailrec
    def loop(target: Option[String],
             count: Int,
             scraps: Vector[Scrap]): Vector[Scrap] = {
      target match {
        case Some(url) =>
          val (next, scrap) = scrape(driver, url, count, strategy)
          // Batch ETLs
          if ((count - startCount) < ETL_BATCH_SIZE) {
            // Be like human sleep sometime between 0 and 5 seconds
            Thread.sleep(Random.nextInt(5) * 1000L)
            loop(next, count + 1, scraps :+ scrap)
          } else {
            scraps :+ scrap
          }
        case None =>
          logger.info("Lurk Accomplished")
          scraps
      }
    }
    loop(Some(startUrl), startCount, Vector.empty[Scrap])
  }

  /**
    * Scrape function uses webdriver to render pages and extract desired
    * information from the DOM.
    * @param driver WebDriver using Selenium.
    * @param url String location of content.
    * @param count The comic strip number being tracked.
    * @param strategy Strategy object containing xpath selectors.
    * @return (Option[String], Scrap) an optional next url and the resultant
    *         Scrap object.
    */
  private def scrape(driver: WebDriver,
                     url: String,
                     count: Int,
                     strategy: Strategy): (Option[String], Scrap) = {
    logger.info(s"Scraping url: $url")

    def judge(selectorsO: Option[Vector[String]],
              htmlectomy: WebElement => Option[String]): Option[String] = {
      selectorsO match {
        case None => None
        case Some(selectors) =>
          selectors
            .flatMap { (selector: String) =>
              val elements: Vector[WebElement] =
                driver.findElements(By.xpath(selector)).asScala.toVector
              elements.map { (element: WebElement) =>
                htmlectomy(element)
              }
            }
            .headOption
            .flatten
      }
    }

    driver.navigate().to(url)
    val checksum = MessageDigest
      .getInstance("MD5")
      .digest(driver.getPageSource.getBytes("UTF-8"))
      .map("%02x".format(_))
      .mkString
    val next = judge(
      Some(strategy.next),
      webElement => Option(webElement.getAttribute("href"))) match {
      case Some(n) if n.nonEmpty && (n == url || n == url + "#") => None
      case _ @n => n
    }
    val (image, isSpecial) = judge(
      Some(strategy.image),
      webElement => Option(webElement.getAttribute("src"))) match {
      case None => (Vector(""), true) // Get Screenshot here
      case Some(i) => (Vector(i), false)
    }
    val title = judge(strategy.title, webElement => Option(webElement.getText))
    val bonusImage = judge(
      strategy.bonusImage,
      webElement => Option(webElement.getAttribute("src")))
    val imageTitle = judge(
      strategy.imageTitle,
      webElement => Option(webElement.getAttribute("title")))
    val imageAlt = judge(strategy.imageAlt,
                         webElement => Option(webElement.getAttribute("alt")))

    val scrap = Scrap(count,
                      checksum,
                      url,
                      image,
                      title,
                      imageTitle,
                      imageAlt,
                      bonusImage,
                      isSpecial)
    logger.info(s"Obtained scrap: $scrap")
    (next, scrap)
  }

  /**
    * Transform, collect all strip information and do any image processing.
    * @param comic Comic object for strip list.
    * @param scraps Scrap Vector of results.
    * @return
    */
  private def transform(comic: Comic,
                        scraps: Vector[Scrap]): Future[Vector[Strip]] =
    Future {
      scraps.map { scrap =>
        // TODO: Generate thumbnail and other potential post processing
        val strip = Strip(ObjectId.get, comic.id, "", scrap)
        logger.info(s"Successfully transformed strip: $strip")
        strip
      }
    }

  /**
    * Calls repo to insert comic strips into database
    * @param strips Vector[Strip]
    * @return Vector of Int, indicating success of insert.
    */
  private def load(strips: Vector[Strip]): Future[Vector[Int]] =
    Future.sequence(strips.map { strip =>
      logger.info(s"Inserting strip $strip")
      repo.insertStrip(strip)
    })

  // Launch etl process.
  // Await sequenced future results before shutting down.
  Await.result(etl(comics), Duration.Inf)
  // Safely close database connection pool.
  repo.shutdown()
  // Exit successfully.
  sys.exit(0)
}
